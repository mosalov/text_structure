{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipymarkup import show_dep_ascii_markup, show_dep_markup, show_span_box_markup\n",
    "from ipymarkup.palette import palette, BLUE, RED, GREEN\n",
    "from razdel import sentenize, tokenize\n",
    "from navec import Navec\n",
    "from slovnet import Syntax\n",
    "from yargy import Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dostoevsky.tokenization import RegexTokenizer\n",
    "from dostoevsky.models import FastTextSocialNetworkModel\n",
    "import yake\n",
    "from laserembeddings import Laser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "navec = Navec.load('navec_news_v1_1B_250K_300d_100q.tar')\n",
    "syntax = Syntax.load('slovnet_syntax_news_v1.tar')\n",
    "syntax.navec(navec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text = \"За последние 10 лет, во втором десятилетии XXI века, рынок стартапов и венчурного инвестирования для многих незаметно, но кардинально изменился. Парадигмой пионеров интернета было создать проект, который изменит интернет к лучшему — «сделать новый Google» (новый Facebook, новый YouTube, новый айфон и так далее). Новой парадигмой стартапера, задумывающегося о своём вкладе в интернет, вступившей в силу в последнее десятилетие, стало создать проект, который будет куплен «Гуглом», «Фейсбуком», Apple (или «Яндексом» или Mail.ru в случае Рунета). Об изменении мира или хотя бы интернета речи уже не идёт — мир уже изменился, а в процессе был открыт, изучен и поделён. Все точки входа и торговые пути под контролем выросших за первые два десятилетия XXI века империй, и новоприбывающим колонистам ничего не остаётся, кроме как выбирать, флагу какой из них присягнуть. Для многих людей, включая автора этих строк, заставших нынешние интернет-империи «в коротких штанишках», когда мы дышали с ними одним воздухом интернет-вольницы, а «Гугл» ещё верил в свой девиз Don't be evil, произошедшее преображение оказалось неприятным, болезненным и неожиданным поворотом. И — отрезвляющим. Но, на самом деле, за последние 10 лет не произошло совершенно ничего нового.\"\n",
    "text = \"Минтранс предложил оснастить автомобили сервисов такси устройствами для контроля сонливости водителей. Об этом говорится в проекте федерального закона «О такси», размещённого на сайте проектов нормативно-правовых актов. Законопроект предусматривает, чтобы кузов такси окрашивали по схеме из квадратов контрастных цветов в шахматном порядке. При этом цветовая гамма должна «соответствовать стандартам региона». На крыше автомобиля необходимо размещать опознавательный фонарь оранжевого цвета. Если проект примут, он вступит в силу 1 сентября 2022 года. Действующие ПДД разрешают водителю находиться за рулём суммарно не более десяти часов. Контролируют это с помощью тахографов. Штраф для нарушителей — до 2,5 тысяч рублей.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk = []\n",
    "sentences = []\n",
    "for sent in sentenize(text):\n",
    "    sentence = {}\n",
    "    sentence['text'] = sent.text\n",
    "    sentence['span'] = (sent.start, sent.stop)\n",
    "    sentences.append(sentence)\n",
    "    tokens = [_.text for _ in tokenize(sent.text)]\n",
    "    chunk.append(tokens)\n",
    "chunk[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markup = next(syntax.map(chunk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert CoNLL-style format to source, target indices\n",
    "words, deps = [], []\n",
    "for token in markup.tokens:\n",
    "    words.append(token.text)\n",
    "    source = int(token.head_id) - 1\n",
    "    target = int(token.id) - 1\n",
    "    if source > 0 and source != target:  # skip root, loops\n",
    "        deps.append([source, target, token.rel])\n",
    "show_dep_ascii_markup(words, deps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "show_dep_markup(words, deps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexTokenizer()\n",
    "model = FastTextSocialNetworkModel(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_texts = []\n",
    "for s in sentences:\n",
    "    sent_texts.append(s['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.predict(sent_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "delta = 0.001\n",
    "spans = []\n",
    "for sentence, sentiment in zip(sentences, results):\n",
    "    print(sentence['text'], '\\n', sentiment)\n",
    "    main_sentiment = ''\n",
    "    if sentiment['negative'] > sentiment['positive']:\n",
    "        main_sentiment = 'Negative'\n",
    "    if sentiment['positive'] > sentiment['negative']:\n",
    "        main_sentiment = 'Positive'\n",
    "    if abs(sentiment['positive'] - sentiment['negative']) < delta:\n",
    "        main_sentiment = 'Neutral'\n",
    "    if main_sentiment != '':\n",
    "        spans.append(sentence['span'] + (main_sentiment,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_span_box_markup(text, spans, palette=palette(RED, GREEN, BLUE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "language = \"ru\"\n",
    "max_ngram_size = 4\n",
    "deduplication_thresold = 0.9\n",
    "deduplication_algo = 'seqm'\n",
    "windowSize = 1\n",
    "numOfKeywords = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_extractor = yake.KeywordExtractor(lan=language, n=max_ngram_size, dedupLim=deduplication_thresold, dedupFunc=deduplication_algo, windowsSize=windowSize, top=numOfKeywords, features=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "keywords = kw_extractor.extract_keywords(text)\n",
    "keywords.sort(key = lambda t: t[1])\n",
    "for kw in keywords :\n",
    "    print(kw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "limit = 0.01\n",
    "\n",
    "for (text, value) in keywords :\n",
    "    if (value < limit) :\n",
    "        print(text, ' : ', value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laser = Laser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = laser.embed_sentences(sent_texts, lang='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(embeddings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
